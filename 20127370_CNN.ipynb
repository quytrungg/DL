{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <u>Bước 1</u>: Import các thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ua_fkXLRG44d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-05-06 20:35:21.717516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import datetime as dt\n",
        "import numpy as np\n",
        "from abc import abstractmethod\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model, load_model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <u>Bước 2</u>: Tải bộ dataset MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3PNRKxInbqW",
        "outputId": "223a387d-4a24-4be0-9aca-34500a88a613"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/quytrungg/.pyenv/versions/3.11.2/envs/deep-learning/lib/python3.11/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "# load MNIST dataset\n",
        "mnist = fetch_openml(\"mnist_784\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <u>Bước 3</u>: Tiền xử lý dữ liệu & chia dữ liệu thành 2 tập train và test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30--N8uxqGM6",
        "outputId": "ff5d03f6-69ea-46db-8df1-4fa56e86eb5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(70000, 28, 28, 1)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mnist.data = mnist.data.to_numpy().reshape((-1, 28, 28, 1))\n",
        "mnist.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JMnhIYn87tEp"
      },
      "outputs": [],
      "source": [
        "# split the dataset into training set and validation set\n",
        "train_img, test_img, train_lbl, test_lbl = train_test_split(\n",
        "    mnist.data,\n",
        "    mnist.target,\n",
        "    test_size=1/7.0,\n",
        "    random_state=0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GUCCe0178cMz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 10), (10000, 10))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# convert to one-hot vector\n",
        "train_lbl = to_categorical(train_lbl)\n",
        "test_lbl = to_categorical(test_lbl)\n",
        "train_lbl.shape, test_lbl.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((60000, 28, 28, 1), (10000, 28, 28, 1), (60000, 10), (10000, 10))"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check size\n",
        "train_img.shape, test_img.shape, train_lbl.shape, test_lbl.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <u>Bước 4</u>: Xây dựng 3 mô hình sử dụng fully connected và convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AbstractModel:\n",
        "    \"\"\"Abstract model architecture class.\"\"\"\n",
        "\n",
        "    model = None\n",
        "    log_dir = \"logs/\" + dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir=log_dir,\n",
        "        histogram_freq=1,\n",
        "    )\n",
        "\n",
        "    @abstractmethod\n",
        "    def __init__(self, kernel_height: int, kernel_width: int) -> None:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def compile(self, loss: str, optimizer: str, metrics: list[str]) -> None:\n",
        "        \"\"\"Compile and summarize initial layers in the model.\"\"\"\n",
        "        self.model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "        self.model.summary()\n",
        "\n",
        "    def fit(\n",
        "        self,\n",
        "        X_train: np.ndarray,\n",
        "        y_train: np.ndarray,\n",
        "        X_test: np.ndarray,\n",
        "        y_test: np.ndarray,\n",
        "        epochs: int,\n",
        "        batch_size: int,\n",
        "    ) -> None:\n",
        "        \"\"\"Train model with training set and evaluate with validation set.\"\"\"\n",
        "        self.model.fit(\n",
        "            X_train,\n",
        "            y_train,\n",
        "            validation_data=(X_test, y_test),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=[self.tensorboard_callback],\n",
        "        )\n",
        "\n",
        "    def accuracy(self, X_test: np.ndarray, y_test: np.ndarray) -> float:\n",
        "        \"\"\"Return the final model's accuracy.\"\"\"\n",
        "        _, accuracy = self.model.evaluate(X_test, y_test)\n",
        "        return accuracy\n",
        "\n",
        "    def save_weights(self, filename: str) -> None:\n",
        "        self.model.save_weights(filename)\n",
        "\n",
        "    def save(self, filename: str) -> None:\n",
        "        self.model.save(filename, include_optimizer=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Mô hình 1 và nhận xét**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model1(AbstractModel):\n",
        "    \"\"\"Architecture for Model1.\n",
        "\n",
        "    This model includes:\n",
        "        - 1 Conv2D layer (50 filters, strides 3x3, ReLU activation)\n",
        "        - 1 Conv2D layer (50 filters, strides 2x2, ReLU activation)\n",
        "        - 2 MaxPooling2D layers (size 2x2)\n",
        "        - 1 Flatten layer\n",
        "        - 1 Dense layer (256 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (128 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (64 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (10 perceptrons, Softmax activation)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_height: int, kernel_width: int) -> None:\n",
        "        \"\"\"Initialize layers in the model.\"\"\"\n",
        "        self.input_layer = Input(shape=(kernel_height, kernel_width, 1))\n",
        "        self.conv_layer = Conv2D(50, (3, 3), activation=\"relu\", padding=\"same\")(self.input_layer)\n",
        "        self.pooling_layer = MaxPooling2D((2, 2))(self.conv_layer)\n",
        "        self.conv_layer_2 = Conv2D(50, (2, 2), activation=\"relu\", padding=\"same\")(self.pooling_layer)\n",
        "        self.pooling_layer_2 = MaxPooling2D((2, 2))(self.conv_layer_2)\n",
        "        self.flatten_layer = Flatten()(self.pooling_layer_2)\n",
        "        self.dense_layer = Dense(256, activation=\"relu\")(self.flatten_layer)\n",
        "        self.dense_layer_2 = Dense(128, activation=\"relu\")(self.dense_layer)\n",
        "        self.dense_layer_3 = Dense(64, activation=\"relu\")(self.dense_layer_2)\n",
        "        self.output_layer = Dense(10, activation=\"softmax\")(self.dense_layer_3)\n",
        "        self.model = Model(inputs=self.input_layer, outputs=self.output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 28, 28, 50)        500       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 50)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 50)        10050     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 50)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2450)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               627456    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 679,808\n",
            "Trainable params: 679,808\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "30/30 [==============================] - 24s 731ms/step - loss: 4.1291 - accuracy: 0.5708 - val_loss: 0.4727 - val_accuracy: 0.8643\n",
            "Epoch 2/5\n",
            "30/30 [==============================] - 27s 919ms/step - loss: 0.2929 - accuracy: 0.9139 - val_loss: 0.1921 - val_accuracy: 0.9431\n",
            "Epoch 3/5\n",
            "30/30 [==============================] - 43s 1s/step - loss: 0.1406 - accuracy: 0.9575 - val_loss: 0.1259 - val_accuracy: 0.9629\n",
            "Epoch 4/5\n",
            "30/30 [==============================] - 34s 1s/step - loss: 0.0910 - accuracy: 0.9726 - val_loss: 0.0988 - val_accuracy: 0.9712\n",
            "Epoch 5/5\n",
            "30/30 [==============================] - 30s 986ms/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 0.0827 - val_accuracy: 0.9765\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0827 - accuracy: 0.9765\n",
            "Model Accuracy: 0.9764999747276306\n"
          ]
        }
      ],
      "source": [
        "model1 = Model1(28, 28)\n",
        "model1.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model1.fit(train_img, train_lbl, test_img, test_lbl, 5, 2000)\n",
        "print(f\"Model Accuracy: {model1.accuracy(test_img, test_lbl)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nhận xét**:\n",
        "- Tổng số lượng params: **679,808**\n",
        "- Model 1 có cấu trúc gồm 2 lớp Convolution và 4 lớp Dense (fully connected), tuy đã có 2 lớp Max Pooling nhưng tổng số lượng param vẫn khá nhiều so số lượng perceptrons trong lớp Dense cao. Về tổng quan thì model này tập trung nhiều vào các lớp Dense.\n",
        "- Chính vì vậy, mô hình cho ra độ chính xác khá cao với xấp xỉ 97,6%, đồng thời tốc độ chạy nhanh (5 epochs và batch size 2000 chạy trong khoảng dưới 3 phút)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Mô hình 2 và nhận xét**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model2(AbstractModel):\n",
        "    \"\"\"Architecture for Model2.\n",
        "\n",
        "    This model includes:\n",
        "        - 1 Conv2D layer (32 filters, strides 3x3, ReLU activation)\n",
        "        - 1 Conv2D layer (64 filters, strides 2x2, ReLU activation)\n",
        "        - 2 BatchNormalization layers (used after each Conv2D layer)\n",
        "        - 2 MaxPooling2D layers (size 2x2, used after each BatchNormalization layer)\n",
        "        - 1 Flatten layer\n",
        "        - 1 Dense layer (32 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (10 perceptrons, Softmax activation)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_height: int, kernel_width: int) -> None:\n",
        "        \"\"\"Initialize layers in the model.\"\"\"\n",
        "        self.input_layer = Input(shape=(kernel_height, kernel_width, 1))\n",
        "        self.conv_layer = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(self.input_layer)\n",
        "        self.batch_layer = BatchNormalization()(self.conv_layer)\n",
        "        self.pooling_layer = MaxPooling2D((2, 2))(self.batch_layer)\n",
        "        self.conv_layer_2 = Conv2D(64, (2, 2), activation=\"relu\", padding=\"same\")(self.pooling_layer)\n",
        "        self.batch_layer_2 = BatchNormalization()(self.conv_layer_2)\n",
        "        self.pooling_layer_2 = MaxPooling2D((2, 2))(self.batch_layer_2)\n",
        "        self.flatten_layer = Flatten()(self.pooling_layer_2)\n",
        "        self.dense_layer = Dense(32, activation=\"relu\")(self.flatten_layer)\n",
        "        self.output_layer = Dense(10, activation=\"softmax\")(self.dense_layer)\n",
        "        self.model = Model(inputs=self.input_layer, outputs=self.output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 28, 28, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 14, 14, 64)        8256      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                100384    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,674\n",
            "Trainable params: 109,482\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "60/60 [==============================] - 46s 742ms/step - loss: 0.5614 - accuracy: 0.8306 - val_loss: 0.5188 - val_accuracy: 0.8518\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 46s 771ms/step - loss: 0.1121 - accuracy: 0.9680 - val_loss: 0.1883 - val_accuracy: 0.9445\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 43s 721ms/step - loss: 0.0688 - accuracy: 0.9795 - val_loss: 0.0897 - val_accuracy: 0.9742\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 44s 734ms/step - loss: 0.0496 - accuracy: 0.9855 - val_loss: 0.0687 - val_accuracy: 0.9794\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 43s 712ms/step - loss: 0.0372 - accuracy: 0.9895 - val_loss: 0.0569 - val_accuracy: 0.9819\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 39s 651ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 0.0503 - val_accuracy: 0.9848\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 43s 720ms/step - loss: 0.0225 - accuracy: 0.9939 - val_loss: 0.0487 - val_accuracy: 0.9850\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 41s 679ms/step - loss: 0.0175 - accuracy: 0.9955 - val_loss: 0.0469 - val_accuracy: 0.9844\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 45s 748ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0452 - val_accuracy: 0.9858\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 45s 743ms/step - loss: 0.0112 - accuracy: 0.9976 - val_loss: 0.0433 - val_accuracy: 0.9872\n",
            "313/313 [==============================] - 5s 15ms/step - loss: 0.0433 - accuracy: 0.9872\n",
            "Model Accuracy: 0.9872000217437744\n"
          ]
        }
      ],
      "source": [
        "model2 = Model2(28, 28)\n",
        "model2.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model2.fit(train_img, train_lbl, test_img, test_lbl, 10, 1000)\n",
        "print(f\"Model Accuracy: {model2.accuracy(test_img, test_lbl)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nhận xét**:\n",
        "- Tổng số lượng params: **109,482**\n",
        "- Model 2 tập trung vào việc tăng số filter (32 và 64) trong lớp Convolution, giảm bớt các lớp Dense. Ngoài ra, model còn làm cân bằng các trọng số và tăng tốc độ training bằng 2 lớp Batch Normalization sau mỗi lớp tích chập. Chính vì vậy mà số lượng param của model 2 ít hơn nhiều so với model 1.\n",
        "- Mô hình cho ra độ chính xác cao hơn Model 1 với xấp xỉ 98,7% accuracy (tập train có độ chính xác hơn 99%), tốc độ training cũng ngang với model 1 (10 epochs và batch size 1000 trong khoảng hơn 7 phút).\n",
        "- Chung quy lại, mô hình 2 có hiệu suất rất tốt khi chỉ có số lượng param không quá nhiều nhưng đạt được độ chính xác cao, đồng thời tốc độ training cũng nhanh nhờ vào số param ít."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Mô hình 3 và nhận xét**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model3(AbstractModel):\n",
        "    \"\"\"Architecture for Model3.\n",
        "\n",
        "    This model includes:\n",
        "        - 1 Conv2D layer (64 filters, strides 3x3, ReLU activation)\n",
        "        - 1 Conv2D layer (128 filters, strides 3x3, ReLU activation)\n",
        "        - 1 SeparableConv2D layer (256 filters, strides 2x2, ReLU activation)\n",
        "        - 3 BatchNormalization layers (used after each Conv2D/SeparableConv2D layer)\n",
        "        - 2 MaxPooling2D layers (size 2x2, used after each BatchNormalization layer)\n",
        "        - 1 Flatten layer\n",
        "        - 1 Dense layer (128 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (64 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (32 perceptrons, ReLU activation)\n",
        "        - 1 Dense layer (10 perceptrons, Softmax activation)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_height: int, kernel_width: int) -> None:\n",
        "        \"\"\"Initialize layers in the model.\"\"\"\n",
        "        self.input_layer = Input(shape=(kernel_height, kernel_width, 1))\n",
        "        self.conv_layer = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(self.input_layer)\n",
        "        self.batch_layer = BatchNormalization()(self.conv_layer)\n",
        "        self.pooling_layer = MaxPooling2D((2, 2))(self.batch_layer)\n",
        "        self.conv_layer_2 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(self.pooling_layer)\n",
        "        self.batch_layer_2 = BatchNormalization()(self.conv_layer_2)\n",
        "        self.pooling_layer_2 = MaxPooling2D((2, 2))(self.batch_layer_2)\n",
        "        self.sepconv_layer = SeparableConv2D(256, (2, 2), activation=\"relu\", padding=\"same\")(self.pooling_layer_2)\n",
        "        self.batch_layer_3 = BatchNormalization()(self.sepconv_layer)\n",
        "        self.flatten_layer = Flatten()(self.batch_layer_3)\n",
        "        self.dense_layer = Dense(128, activation=\"relu\")(self.flatten_layer)\n",
        "        self.dense_layer_2 = Dense(64, activation=\"relu\")(self.dense_layer)\n",
        "        self.dense_layer_3 = Dense(32, activation=\"relu\")(self.dense_layer_2)\n",
        "        self.output_layer = Dense(10, activation=\"softmax\")(self.dense_layer_3)\n",
        "        self.model = Model(inputs=self.input_layer, outputs=self.output_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 14, 14, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " separable_conv2d (Separable  (None, 7, 7, 256)        33536     \n",
            " Conv2D)                                                         \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 7, 7, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               1605760   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,726,250\n",
            "Trainable params: 1,725,354\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "30/30 [==============================] - 156s 5s/step - loss: 0.5570 - accuracy: 0.8281 - val_loss: 1.2481 - val_accuracy: 0.7876\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 138s 4s/step - loss: 0.0640 - accuracy: 0.9821 - val_loss: 1.0946 - val_accuracy: 0.8588\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 140s 5s/step - loss: 0.0321 - accuracy: 0.9908 - val_loss: 0.9059 - val_accuracy: 0.9552\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 136s 5s/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.6979 - val_accuracy: 0.9769\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 270s 9s/step - loss: 0.0107 - accuracy: 0.9977 - val_loss: 0.5180 - val_accuracy: 0.9829\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 140s 5s/step - loss: 0.0060 - accuracy: 0.9991 - val_loss: 0.3635 - val_accuracy: 0.9845\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 156s 5s/step - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.2254 - val_accuracy: 0.9879\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 154s 5s/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 0.1404 - val_accuracy: 0.9884\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 143s 5s/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0885 - val_accuracy: 0.9890\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 125s 4s/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0611 - val_accuracy: 0.9901\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.0611 - accuracy: 0.9901\n",
            "Model Accuracy: 0.9901000261306763\n"
          ]
        }
      ],
      "source": [
        "model3 = Model3(28, 28)\n",
        "model3.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model3.fit(train_img, train_lbl, test_img, test_lbl, 10, 2000)\n",
        "print(f\"Model Accuracy: {model3.accuracy(test_img, test_lbl)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Nhận xét**:\n",
        "- Tổng số lượng params: **1,725,354**\n",
        "- Ở mô hình 3, số lượng layer được thiết lập dày đặc nhất, với 4 lớp Dense, lần lượt có 128, 64, 32 và 10 perceptrons, đồng thời có 2 lớp Convolution với số lớp filter cao (64 và 128 filter), 2 lớp Batch Normalization để cân bằng trọng số sau mỗi lớp Convolution.\n",
        "- Ngoài ra, mô hình 3 còn được gắn thêm 1 lớp Separable Convolution để giảm bớt số lượng param mà vẫn cho ra cùng độ accuracy, tuy nhiên do quá nhiều lớp chồng lên nhau mà tổng số lương param nhiều nhất trong cả 3 mô hình.\n",
        "- Mô hình 3 chạy chậm nhất (10 epoch, 2000 batch size nhưng thời gian training hơn 20 phút), bù lại cho ra độ chính xác cao nhất với 99% accuracy, trong đó accuracy trên tập train là gần như 100%.\n",
        "- Tóm lại, ta có thể thấy được việc tăng số layer cho mô hình, đặc biệt là số lớp Dense sẽ làm cho mô hình có độ chính xác cao hơn, nhưng đánh đổi lại là tốc độ training lâu hơn khá nhiều."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Bảng so sánh**\n",
        "\n",
        "| **Model** | **Params** | **Accuracy (%)** | **Avg Time** |            **Note**           |\n",
        "|:---------:|:----------:|------------------|:--------:|:-----------------------------:|\n",
        "|   Model1  |   679,808  |     ~97,6     |  2m 42s (5 epochs)  | Fastest time, Lowest accuracy |\n",
        "|   Model2  |   109,482  |     ~98,7     |  7m 22s (10 epochs) | Least parameters, Best effiency (Time & Accuracy) |\n",
        "|   Model3  |  1,725,354 |     ~99,0     |  26m 10s (10 epochs) | Lowest time, Highest accuracy |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
